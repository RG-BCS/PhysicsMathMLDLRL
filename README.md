# Hi there, I’m PhysicsMathMLDLRL 

I’m a physicist turned self-taught Machine Learning engineer passionate about bridging theory and practice.

- Currently building and deploying projects across Traditional ML, Deep Learning, Reinforcement Learning, and Generative Models.
- I’ve built a strong foundation through self-study—starting with Learning Python to master the language itself—then diving into core texts like Hands-On Machine Learning, Deep Learning by Goodfellow, and a wide range of resources to go deep into machine learning, deep learning, and reinforcement learning.
- Projects include building a small GPT-2 style language model, several GAN variants (DCGAN, StyleGAN, CycleGAN), deep learning architectures such as CNNs, RNNs, LSTMs, GRUs, seq2seq models with and without attention for neural machine translation, Autoencoders and Variational Autoencoders (VAEs), customized implementations of traditional machine learning algorithms, and reinforcement learning agents applying algorithms like DQN and PPO.
- Focused on creating real-world applications grounded in solid mathematical and physical principles.

## My Self-Study Journey

As a self-taught ML engineer, I have studied a comprehensive range of foundational and advanced books, including:

- *Learning Python* by Mark Lutz  
- *Introduction to Machine Learning with Python* by Andreas C. Müller & Sarah Guido  
- *Machine Learning with Scikit-Learn and PyTorch* by Sebastian Raschka & Yuxi (Hayden) Liu  
- *Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow* by Aurélien Géron  
- *Deep Learning* by Ian Goodfellow, Yoshua Bengio, and Aaron Courville  
- *Deep Learning with Python* by François Chollet  
- *Advanced Deep Learning with Python* by Ivan Vasilev, Daniel Slater, Gianmario Spacagna, Peter Roelants, and Valentino Zocca  
- *Designing Machine Learning Systems* by Chip Huyen  
- *Pattern Recognition and Machine Learning* by Christopher M. Bishop  
- *Building Large Language Models* by Sebastian Raschka (2025)  

This rigorous self-study has equipped me to build projects spanning traditional ML, deep learning architectures including transformers, CNNs, RNNs, LSTMs, GRUs, GANs, VAEs, reinforcement learning, and language models.

---

## Technical Strengths

- **Languages**: Python (NumPy, Pandas, Matplotlib, etc.)
- **Frameworks**: PyTorch, TensorFlow, Keras, Scikit-learn, OpenAI Gym
- **Core Areas**:
  - Supervised / Unsupervised ML
  - Deep Learning Architectures (CNNs, RNNs, Transformers, GPT)
  - Autoencoders, VAEs, GANs
  - Reinforcement Learning (Q-learning, DQN, PPO, Actor-Critic)
  - Natural Language Processing (Seq2Seq, Attention, Transformers)
---
## Projects Roadmap

### Traditional Machine Learning
- Classic ML algorithms & data science projects
- Feature engineering and model optimization
- Custom implementations of algorithms

### Deep Learning & Generative Models
- Neural networks with TensorFlow and PyTorch
- GANs and their variants
- NLP and small language models

### Reinforcement Learning
- Algorithms for sequential decision-making and control
- Implementations of state-of-the-art RL techniques

## How to reach me
Feel free to connect email me at nattyhena@yahoo.com 

---

*Thanks for visiting my profile! Feel free to explore my projects below.*

